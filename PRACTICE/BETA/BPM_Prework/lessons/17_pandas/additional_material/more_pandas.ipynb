{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purpose:__ The purpose of this lecture is to explore the extremely powerful Python package - Pandas. We will learn what Pandas is, why it is so useful for Data Scientists, how to use Pandas Series and DataFrames for indexing and manipulation tasks and more advanced capabilities like grouping, aggregating, and sorting.  \n",
    "\n",
    "__At the end of this lecture you will be able to:__\n",
    "> 1. Understand what the Pandas Package is and what it can be used for \n",
    "> 2. Understand the concept of a Pandas Series and Pandas DataFrame and how they can be created, accessed, and manipulated\n",
    "> 3. Perform indexing and manipulation (concatenating/merging/joining/reshaping) tasks on Pandas DataFrames\n",
    "> 4. Perform advanced tasks on Pandas DataFrames such as aggregating and grouping \n",
    "> 5. Use Pandas built-in capabilities for Time Series data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Introduction and Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__\n",
    "- __[Pandas](http://pandas.pydata.org/pandas-docs/stable/index.html):__ Pandas is a Python package that provides fast and flexible data structures that are designed to make working with [relational](https://en.wikipedia.org/wiki/Relational_database) or \"labeled\" data easy and intuitive\n",
    "- In the words of [Wes McKinney](https://en.wikipedia.org/wiki/Wes_McKinney), who created Pandas in 2008, and published [this](http://www.dlr.de/sc/Portaldata/15/Resources/dokumente/pyhpc2011/submissions/pyhpc2011_submission_9.pdf) paper in 2011 at PyHPC describing the usefulness and need for Pandas (which was a play on [__Pan__ el __Da__ ta](https://en.wikipedia.org/wiki/Panel_data) )\n",
    "\n",
    "_\"Pandas enables people to analyze and work with data who are not expert computer scientists...the code is intuitive and accessible. Pandas helps people move beyond just using Excel for data analysis\"_ \n",
    "\n",
    "- When Python was first developed, it was very difficult to perform tasks such as importing CSV files, dealing with spreadsheet-like datasets with rows and columns and merging tables \n",
    "- Therefore, Pandas was developed to solve these problems and with the introduction of the DataFrame, Pandas made it possible to do intuitive analysis and exploration in Python that was not possible and still not possible in other languages \n",
    "- In recent years, the Pandas Package has become a staple in the Data Scientist's toolbox for some of the following reasons. In fact, Python is one of the most popular programming languages for Data Scientists specifically because of packages such as Pandas and Matplotlib (Lecture 6)\n",
    "> 1. As a Data Scientist, it is common to work with tabular data where the data in each column is different, known as __hetereogenously-typed data__ (similar to a SQL table or Excel spreadsheet). Pandas DataFrame replicates tabular data and allows you to do everything you would in a spreadsheet, but better and faster \n",
    "> 2. As a Data Scientist, it is common to work with time series data that may be ordered or unordered and Pandas has extensive capabilities to treat dates, times, etc. \n",
    "> 3. The most time-consuming part of any Data Scientist's job is __[Data Munging](https://en.wikipedia.org/wiki/Data_wrangling)__ (Data Cleaning/Wrangling) and Pandas provides all the necessary tools at your fingertips to do this quicker and cleaner \n",
    "> 4. Exploratory Data Analysis is often overlooked in Data Science, but remains one of the most important tasks of a Data Scientist and Pandas provides many easy and intuitive methods to perform data manipulation \n",
    "\n",
    "- Now you understand why Data Scientists use the Pandas Package, but what is it about the Pandas Package that allow us, as users of the Pandas Package, to realize these benefits? \n",
    "> 1. __Missing Data:__ Pandas handles missing data well (represented as NaN - recall NumPy missing value)\n",
    "> 2. __Size Mutability:__ Pandas DataFrames are size mutable which means columns and rows can be inserted and deleted \n",
    "> 3. __Data Aligment:__ Pandas allows you to align an object to a specific set of labels OR allow Pandas align the data for you\n",
    "> 4. __Grouping Data:__ Pandas `groupby` function allows both aggregating and transforming of data \n",
    "> 5. __Data Access:__ Pandas has extensive capabilities of slicing, indexing and subsetting large data sets \n",
    "> 6. __Reshaping Data:__ Pandas has extensive capabilities of merging, joining, and reshaping data \n",
    "> 7. __Input/Output:__ Pandas allows easy import and export of flat files such as CSV \n",
    "> 8. __Time-Series:__ Pandas has specific Time-Series functionality to work with dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data Structures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__ \n",
    "- Recall that the usefulness of Pandas has to do with its fundamental data structures\n",
    "- There are 2 types of data structures in Pandas:\n",
    "> 1. [`Series`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html#pandas.Series): Series is a one-dimensional labeled array that is capable of holding any data type (i.e. `int`, `str`, `float`, etc.), but every element is of this same type. The axis labels of a Series are referred to as the __Index__ of the Series\n",
    ">> - The `pd.Series(data, index)` function which creates a Series data structure, has 2 arguments:<br>\n",
    ">> a. `index`: The `index` argument is a list of axis labels<br>\n",
    ">> b. `data`: The `data` argument can be any of the following:\n",
    ">> > 1. Python dictionary (`dict`)\n",
    ">> > 2. NumPy Array (`ndarray`)\n",
    ">> > 3. Scalar value (5)<br> \n",
    "> 2. [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html): Dataframe is a two-dimensional labeled data structure with columns of potentially different types. It largely resembles a spreadsheet or SQL table. The first axis labels of a Dataframe (rows) are referred to as the __Index__ of the Series, whereas the second axis labels labels of a Dataframe (columns) are referred to as the __Columns__ of the Series\n",
    ">> - The `pd.DataFrame(data, index, columns)` function which creates a Dataframe data structure, has 3 arguments:<br>\n",
    ">> a. `index`: The `index` argument is a list of axis 0 labels<br>\n",
    ">> b. `columns`: The `column` argument is a list of axis 1 labels<br>\n",
    ">> c. `data`: The `data` argument can be any of the following:\n",
    ">> > 1. Dictionary of 1D ndarrays, lists, dicts, or Series \n",
    ">> > 2. 2-D NumPy Array (`ndarray` object) \n",
    ">> > 3. A `Series` object \n",
    ">> > 4. Another `DataFrame` object\n",
    ">> > 5. List of Python dictionaries \n",
    ">> > 6. From CSV or Excel file (or any of the possible file formats which can be found [here](http://pandas.pydata.org/pandas-docs/stable/io.html)\n",
    "\n",
    "__Helpful Points:__\n",
    "1. Remember that data alignment in Pandas is intrinsic which means that the link between labels and data will not be broken unless you do so explicitly \n",
    "2. If you pass an index and/or columns into the function, you guarantee these in the resulting object. Therefore, if you also pass a dictionary, for example, you will lose all the data from the dictionary that does not match with the passed index  \n",
    "3. If axis labels are not passed into the function, they will be constructed from the input data \n",
    "4. We will see examples of creating both types of data structures below \n",
    "\n",
    "__Practice:__ Examples of creating Pandas Data Structures in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (Creating Series in Pandas):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series from Python Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"Gordon\": 20, \"Roberto\": 10, \"Jerod\":15}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_series_1 = pd.Series(my_dict)\n",
    "ex_series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(my_dict, index = [\"Jerod\", \"Bob\", \"Mary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Helpful Point 2\" above which states that if you pass an index into the function (`[\"Jerod\", \"Bob\", \"Mary\"]`), you guarantee these indexes in the resulting object, whether they existed in your data or not. We passed in a dictionary of data that only had 1 of 3 indexes the same as the `index` argument. Therefore, the remaining indexes that were passed in, but not in the data are shown with `NaN` to represent \"missing data\" and the remaining indexes that were in the data, but not passed in, are simply not shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series from NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.arange(2,6)\n",
    "print(my_array, type(my_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_1 = pd.Series(my_array) # no index argument so Pandas will infer it \n",
    "pd_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Helpful Point 3\" above which states that if you do not pass an index into the function, the indexes will be constructed. They are constructed with value from `[0, ..., len(data) - 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_2 = pd.Series(my_array, index = [\"a\", \"b\", \"c\", \"d\"]) # explicitly define index argument \n",
    "pd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_2.index # extract the index labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Series from Scalar Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scalar = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(my_scalar) # no index provided, length equal to 1 by default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(my_scalar, index = [0,0,0,1,1]) # index provided with length 5, match this length in Series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two points here:\n",
    "\n",
    "1. It is possible to have non-unique index values (i.e. index passed in repeats both 0s and 1s). If you peform an operation on a Pandas Series or DataFrame object with non-unique index names and the operation requires unique index names, you will receive an error only at the time. However, most operations don't actually use the index name, therefore it is not that important\n",
    "2. If you create a Series object based on scalar value, the scalar will be repeated as many times as required to match the length of the index. If no index is given, a default length of 1 occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Series Name Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series(my_scalar, index = [0,0,0,1,1], name = \"Name1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_series.name,'\\n')\n",
    "print(my_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1 = my_series.rename(\"Name2\") # rename the name attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(my_series_1.name,'\\n')\n",
    "print(my_series_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Name Attribute will come in handy to understand when we look at DataFrames since each column of a DataFrame is a Series Object with the Name Attribute equal to the column name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (Creating DataFrames in Pandas):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"ndarray\":np.arange(4), # first value is ndarray \n",
    "           \"List\":[10,12,1,2], # second value is list \n",
    "           \"Series\":pd.Series('a', index = [\"row_1\", \"row_2\", \"row_3\", \"row_4\"])} # third value is pandas series \n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few points here:\n",
    "\n",
    "1. We can see that to create this dataframe from a dictionary that has a NumPy Array, List, and Series object, we need all objects to have the same length (4) which corresponds to the number of rows\n",
    "2. The index of the Series object was explicitly assigned index labels, therefore they were not imputed\n",
    "3. Each key-value pair in the dictionary becomes a column in the associated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.dtypes # types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.index # row names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.columns # column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.arange(4).reshape(2,2)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(my_array, index = [\"row_1\", \"row_2\"], columns = [\"column_1\", \"column_2\"])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Series Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series(my_scalar, index = [0,0,0,1,1])\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(my_series, columns = [\"column_1\"])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from other DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame(df_2, columns = [\"new_column_1\"])\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the column labels were passed into the function, these have now been explicitly defined and the new dataframe must have the same index labels AND column labels, otherwise it will appear as missing data, which it does here (`NaN`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from List of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [{\"First\":\"Gordon\", \"Last\":\"Dri\"},\n",
    "           {\"First\":\"Roberto\", \"Last\":\"Reif\"},\n",
    "           {\"First\":\"Jerod\", \"Last\":\"Rubalcava\"}]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(my_list, index = [\"Employee_1\", \"Employee_2\", \"Employee_3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each item in the list turns out to be a row in the resulting DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from CSV\n",
    "\n",
    "Pandas has extensive capabilities of reading and writing to different formats. The most common input/output (I/O) that you will perform is with the [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) file format, but Python also supports many other formats shown below, each with their respective reader and writer functions:\n",
    "\n",
    "> 1. __CSV:__ `read_csv` and `to_csv`\n",
    "> 2. __MS Excel:__ `read_excel` and `to_excel`\n",
    "> 3. __Python Pickle:__ `read_pickle` and `to_pickle`\n",
    "> 4. __SQL:__ `read_sql` and `to_sql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below for the CSV file that we will create a DataFrame from: <img src=\"img29.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"csv_file_for_pandas.csv\") # Note: CSV file must be in the same directory as this Jupyter Notebook, otherwise include exact path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pd.read_csv` function assumed that Column A was a column in our data instead of the row labels, so we need to fix this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0) # specify location of row labels (at first column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Pandas Data Structures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__\n",
    "- Pandas offers many ways to \"inspect\" Data Structures which become paramount when peforming Exploratory Data Analysis with Pandas \n",
    "- The following are useful ways of inspecting Pandas Data Structures where `obj` is either a Series or DataFrame Object\n",
    "> 1. __Dimensions:__ Dimensions can be accessed using `len(obj)`, `obj.shape`, and `obj.size`\n",
    "> 2. __Row Labels:__ Row labels can be accessed using `obj.index`, `obj.index.name`\n",
    "> 3. __Column Labels:__ (Only for DataFrames) Column labels can be accessed using `obj.columns`, `obj.columns.values`, `obj.columns.values.tolist()`, `obj.columns.tolist()`\n",
    "> 4. __Name Labels:__ (Only for Series, unless accessing specific columns) Name labels can be accessed using `obj.name`\n",
    "> 5. __Data Values:__ Data values can be accessed using `obj.values` \n",
    "> 6. __Data Type:__ Data types can be accessed using `obj.dtypes`\n",
    "> 7. __Data Quick Look:__  Data quick looks can be accessed using `obj.head(n)`, `obj.tail(n)`\n",
    "> 8. __Data Summary:__ Data summary can be completed by `obj.describe`\n",
    "\n",
    "__Helpful Points:__\n",
    "1. It is possible to inspect both Series and DataFrames, however DataFrames have some additional functions for inspection given that they have an additional dimension and attributes \n",
    "2. Pandas Series and DataFrames will be explored separately below\n",
    "\n",
    "__Practice:__ Examples of Inspecting Pandas Data Structures in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (Inspecting Pandas Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1 = pd.Series([10, 3.2, 6, 1], index = [\"row_1\", \"row_2\", \"row_3\", \"row_4\"], name = \"Series_1\")\n",
    "my_series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_series_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_series_1.index)\n",
    "print(list(my_series_1.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_series_1.values)\n",
    "type(my_series_1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quick Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_series_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (Inspecting Pandas DataFrames):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quick Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_df.head(2) # first 2 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.tail(1) # last row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.sample(2) # choose any 2 rows randomly (run the cell multiple times and you will see different result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "\n",
    "Only summarizes the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_df.describe() # notice it only does this for the columns that are of dtype = int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing Pandas Data Structures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__ \n",
    "- Pandas offers many different techniques to index (access) elements within Data Structures which can be found [here](http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n",
    "- There are 6 main ways of indexing Pandas data structures:\n",
    "> 1. __Select by Column Name:__ The syntax of this method is `df[col_name]` and it returns a `Series` object\n",
    "> 2. __[Select by Label](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-label):__ This describes __purely label-based indexing__ which selects labels based on what is included in the index of the object. The syntax of this method (for DataFrames) is `df.loc[row_label, column_label]` and it returns a `Series` object. The following provides a list of the possible arguments for the `row_label` and/or `column_label`:\n",
    ">> a. A single label (i.e. `5` or `a`, but the number `5` is interpreted as the label and NOT as the index (use `.iloc` for this)<br>\n",
    ">> b. A list or array of labels (i.e. `['a', 'b', 'c']`)<br>\n",
    ">> c. A slice object with labels (i.e. `['a':'f']`, but unlike with other slices in Python, the `stop` argument is included in the slice)  \n",
    ">> d. A boolean array \n",
    "> 3. __[Select by Integer Location (Position)](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-integer):__ This describes __purely integer-based indexing__ which requires an integer (0-based indexing) for input. The syntax of this method is (for DataFrames) `df.iloc[row_number, column_number]` and it returns a `Series` object. The following provides a list of the possible arguments for `row_number` and/or `column_number`:\n",
    ">> a. An integer (i.e. `5`)<br>\n",
    ">> b. A list or array of integers (i.e. `[4, 3, 0]`<br>\n",
    ">> c. A slice object with integers (i.e. `[1:7]`<br>\n",
    ">> d. A boolean array \n",
    "> 4. __[Slicing Ranges](http://pandas.pydata.org/pandas-docs/stable/indexing.html#slicing-ranges):__ The syntax of this method is (for DataFrames) `df[row_number_1:row_number_2]` and it returns a `DataFrame` object. The `[` and `]` operator is responsible for the slicing and this ONLY operates on rows\n",
    "> 5. __[Boolean Indexing](http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing):__ The syntax of this method is (for DataFrames) `df[boolean_vector]` and it returns a `DataFrame` object. This is performed using boolean operators such as `|` for `or`, `&` for `and` and `~` for not and each must be grouped by parantheseses\n",
    "> 6. __[Indexing with isin](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-with-isin):__ The syntax of this method is (for DataFrames) `df.isin(values)` and it returns a boolean vector that is true wherever the Series elements exist in the passed list \n",
    "\n",
    "__Helpful Points:__\n",
    "1. Recall in previous lectures how we peformeed indexing in Lists, Strings and other ordered, sequence types. The process with Pandas Data Structures is quite similar with a few minor syntactical differences\n",
    "2. Both Series and DataFrames can be indexed, naturally though, Series have less functionality\n",
    "\n",
    "__Practice:__ Examples of Indexing Pandas Data Structures in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (Select by Column Name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a Column by Name - Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[\"Last\"] # 2nd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(employee_df[\"Last\"]) # returns a Series object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a Column by Name - Method 2\n",
    "\n",
    "This option is limited to column names that do not have blank spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.Last # 2nd column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(employee_df.Last) # returns a Series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame([{'First 1':'Roberto','Last_1':'Reif'},{'First 1':'Gordon','Last_1':'Dri'}])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['First 1']\n",
    "# test.First 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Last_1']\n",
    "# test.Last_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Multiple Columns by Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[[\"First\", \"Last\"]] # 1st and 2nd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(employee_df[[\"First\", \"Last\"]]) # returns a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (Select by Label):\n",
    "\n",
    "Recall that any `pandas` object (Series and DataFrames) has an index. The elements in these indexes are called _labels_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Single Label - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[\"b\"] # 2nd row value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[1] # 2nd row value???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will output a (rather lengthy) error message (in times like these, just skip to the very bottom for the actual error info). The reason this results in an error is because when using `loc`, we are indexing by row label so the number `1` is interpreted as a row label and there is clearly not a row label named `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[4] # no error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there IS a row label named `4`, therefore we can index with the integer 4. Make sure you understand though, this is NOT integer indexing and the argument `4` is interpreted as a row label and NOT an integer position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Single Label - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_1\"] # 1st row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_1\", \"First\"] # 1st row, 1st column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with List of Labels - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[[\"a\", \"c\", 4]] # 1st row, 3rd row, last row "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with List of Labels - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[[\"Employee_1\", \"Employee_3\"]] # 1st row and last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[[\"Employee_1\", \"Employee_3\"], [\"Last\", \"Age\"]] # 1st row and last row and last two columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Slice Object - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[\"b\":\"d\"] # 2nd to 4th row, inclusive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Slice Object - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_2\":\"Employee_3\"] # 3rd and 4th row, inclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `stop` argument in the slice `\"Employee_2\":\"Employee_3\"` is included in the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_2\":\"Employee_3\", \"Last\":] # 3rd and 4th row, inclusive and 2nd and 3rd columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the slice `\"Last\":` actually includes the endpoint, which is not the same as regular slicing in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_2\":\"Employee_3\", [\"First\", \"Age\"]] # mix slice object with list of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Boolean Array - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[\"a\"] > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1[series_1 > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Boolean Array - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[:, \"Age\"] > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[employee_df.loc[:, \"Age\"] >30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Scalar Values\n",
    "\n",
    "Indexing the traditional way as we saw above is very versatile, but that comes with a downside - which is that it takes a bit of time to figure out which of the many options are being asked. If you want to only access a __[scalar value](https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html#arrays-scalars)__ using position indexing, the best (and fastest) way it to use the `at` method. This method works in the same way as `loc`, in that it requires labels as arguments and not integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_1\", \"Age\"] # method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.at[\"Employee_1\", \"Age\"] # method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_1\", \"Last\":] # non scalar value is okay for .loc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.at[\"Employee_1\", \"Last\":] # non scalar value is not okay for .at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (Select by Integer Location):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Integer - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iloc[2] # 3rd row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[\"c\"] # same result as above using label-based indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Integer - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[1, 2] # 2nd row, 3rd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_2\",\"Age\"] # same result as above using label-based indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with List of Integers - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1.iloc[[1,2,4]] # 2nd, 3rd and 5th rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with List of Integers - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[[0,2], [1,2]] # 1st row and 3rd row, 2nd and 3rd columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Slice Object - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1.iloc[2:4] # 3rd and 4th rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iloc[2:10] # out-of-bound indexing is handled gracefully like we saw in Lecture 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iloc[10:] # out-of-bound indexing is handled gracefully like we saw in Lecture 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Slice Object - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[1:, :] # 2nd and 3rd rows, all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[1:, [0,1,2]] # mix of slice object and list of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.iloc[:, 2:8] # out-of-bound indexing is handled gracefully like we saw in Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Boolean Array - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iloc[2] > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access with Boolean Array - DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[:, 2] > 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Scalar Values\n",
    "\n",
    "Indexing the traditional way as we saw above is very versatile, but that comes with a downside - which is that it takes a bit of time to figure out which of the many options are being asked. If you want to only access a __[scalar value](https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html#arrays-scalars)__ with integer indexing, the best (and fastest) way it to use the `iat` method. This method works in the same way as `iloc`, in that it requires labels as arguments and not integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.iloc[2, 2] # method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iat[2, 2] # method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[0:2, [0,2]] # non scalar value is okay for .iloc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iat[0:2, [0,2]] # non scalar value is not okay for .at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (Slicing Ranges):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Ranges - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 2, stop = 5, step = 1\n",
    "series_1[2:4] # 3rd row to 5th row (not inclusive) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0, stop = 4, step = 2\n",
    "series_1[::2] # every other row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 4, stop = 0, step = -1 \n",
    "series_1[::-1] # reverse the rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Ranges - DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[1:2] # 2nd row, returns a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[1] # 2nd row, returns a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[::2] # every other row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[::-1] # reverse the rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when slicing ranges using the `[` and `]` operator, without `loc` or `iloc`, the slicing acts on the row and was designed like this since it is such a common operation. Note that you can't access rows AND columns here as we are just subsetting rows. If you would like to access rows AND columns, use `iloc` or `loc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 (Boolean Indexing):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1[series_1 > 4] # all rows greater than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1[(series_1 > 3) & (series_1 < 5)] # all rows greater than 3 AND less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1[~(series_1 == 4)] # all rows not equal to 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing - DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df[employee_df[\"Age\"] > 30] # all rows with age greater than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[(employee_df[\"Age\"] > 30) & (employee_df[\"Age\"] < 50)] # all rows with age greater than 30 and less than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[~(employee_df[\"First\"] == \"Gordon\")] # all rows where first name is not equal to Gordon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df[employee_df[\"First\"] != \"Gordon\"] # all rows where first name is not equal to Gordon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 (Using `isin`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `isin` - Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.isin([3,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1[series_1.isin([3,6,7])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `isin` - DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\"Gordon\", \"Roberto\", \"Reif\", 31] # criteria spans multiple columns, find rows that meet this multi-part criteria \n",
    "employee_df.isin(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'First': ['Gordon', 'Jerod'], 'Age': [31]} # match certain values with certain columns\n",
    "employee_df.isin(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Manipulation of Pandas Data Structures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Overview:__\n",
    "- Pandas offers many useful ways to manipulate both Series and DataFrames:\n",
    "\n",
    "> /1. __Setting Values:__ Pandas offers a few different methods of setting values:\n",
    ">> a. Using __Slicing Ranges__ (i.e. `df[:5] = 0`)<br>\n",
    ">> b. Using __Labels__ (i.e. `df.loc[\"a\":] = 0` or `df.at[\"a\":] = 0`)<br>\n",
    ">> c. Using __Position__ (i.e. `df.iloc[:3] = 0` or `df.iat[:3] = 0`)<br>\n",
    "\n",
    "> /2. __Manipulating Rows:__ Pandas offers many different methods to manipulate rows:\n",
    "\n",
    ">> a. __Changing Row Index:__ \n",
    ">> > 1. Renaming the row index (`df.rename(index=)`)\n",
    ">> > 2. Setting the row index back to 0-based indexing (`df.reset_index(drop=True)`), etc.\n",
    ">> > 3. Re-indexing labels (`df.reindex(index=)`) \n",
    "\n",
    ">> b. __Adding Rows:__\n",
    ">> > 1. Inserting row within the DataFrame (`pd.concat()`)\n",
    ">> > 2. Adding row at the bottom of the DataFrame (`df.append()` or `df.loc[len(df)] = val`)\n",
    "\n",
    ">> c. __Removing Rows:__\n",
    ">> > 1. Removing rows based on row index (`df.drop(df.index[])` or `df.drop([row_name])`)\n",
    "\n",
    ">> d. __Sorting Rows:__\n",
    ">> > 1. Sorting rows based on column values (`df.sort_values(by = [\"col_name_1\", \"col_name_1\"])`)\n",
    ">> > 2. Sorting rows based on labels (`df.sort_index(axis=0)`)\n",
    "\n",
    "> /3. __Manipulating Columns:__ Pandas offers many different methods to manipulate columns:\n",
    "\n",
    ">> a. __Changing Column Names:__ \n",
    ">> > 1. Explicitly assign the column names (`df.columns = [\"new_col_1\", \"new_col_2\"]`)\n",
    ">> > 2. Renaming the columns (`df.rename(columns=)`\n",
    ">> > 3. Re-indexing column names (`df.reindex(columns=)`) \n",
    "\n",
    ">> b. __Adding Columns:__\n",
    ">> > 1. Inserting column within the DataFrame (`df.insert(column_position, column = \"new_col_name\", value = )`)\n",
    ">> > 2. Adding column to the end of the DataFrame (`df[\"new_col_name\"] = pd.Series()`)\n",
    "\n",
    ">> c. __Removing Columns:__\n",
    ">> > 1. Deleting column using `del` (`del df[\"col_name\"]`)\n",
    ">> > 2. Deleting column using `pop` (`df.pop(\"col_name\")`)\n",
    ">> > 3. Removing columns using `drop` (`df.drop([\"col_name_1\", \"col_name_5\"], axis = 1)`)\n",
    "\n",
    ">> d. __Sorting Columns:__\n",
    ">> > 1. Sorting columns based on column names (`df.sort_index(axis=1)`)\n",
    "\n",
    "__Helpful Points:__\n",
    "1. Remember, there are always more than one way to do something in Python and this is especially true with changing, adding, and removing rows/columns in Pandas Series and DataFrames \n",
    "2. Don't worry if you can't remember all these possibilities now, be sure to come back and review this list as needed\n",
    "3. Many of these functions mentioned above act \"in-place\" which means they perform their operation on the actual object itself \n",
    "\n",
    "__Practice:__ Examples of Simple Row/Column Manipulation of Pandas Series and DataFrames in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (Setting Values):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - Slicing Ranges (Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1[:2] = 100 # setting values in first 2 rows \n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - Slicing Ranges (DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df[0:2] = \"New\" # setting values in first 2 rows\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - By Labels (Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.loc[\"a\":\"d\"] = 5 # setting values in first 4 rows using loc \n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.at[4] = 100 # setting scalar value in last row using at \n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - By Labels (DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[\"Employee_2\":\"Employee_3\"] = \"New\" # setting values in last 2 rows using loc \n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.at[\"Employee_1\"] = \"New\" # setting value in first row using at\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - By Position (Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iloc[:2] = 21 # setting values in first 2 rows using iloc \n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.iat[3] = 100 # setting value in 4th row using iat\n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Values - By Position (DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.iloc[2:] = \"New\" # setting value in 3rd row using iloc\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (Manipulating Rows):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Rename - Series\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1.rename({\"a\":\"A\", \"b\":\"B\", \"c\":\"C\", \"d\":\"D\", 4:\"four\"}) # map old index to new index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Rename - DataFrame\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.rename({\"Employee_1\":\"Employee1\", \"Employee_2\":\"Employee2\"})# map old row index to new row index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Reset - Series\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.reset_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])\n",
    "type(series_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_1.reset_index() # resets index and adds a column of old index (returns dataframe), and it is not in place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output is now a DataFrame with one column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Reset - DataFrame\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html#pandas.DataFrame.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.reset_index() # resets index and adds a column of old index. It is not in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-index - Series\n",
    "\n",
    "We can also re-index labels. Note that this can delete data from your series if you aren't careful.\n",
    "\n",
    "- Labels in the new index that appear in the old index will preserve the original data. \n",
    "- New labels will appear with missing values in the data. \n",
    "- Old labels that do not appear in the new index will drop data from the series.\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.reindex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_index = [\"a\", \"b\", \"New_1\", \"New_2\", 4] # change some indexes \n",
    "series_1.reindex(new_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-index - DataFrame\n",
    "\n",
    "(Same principles apply for losing data or adding missing values, but this time across all columns when a new index is added -- indexes in DataFrames point to entire rows.)\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_index = [\"Employee_1\", \"Employee_2\", \"Employee_3\", \"Employee_4\"]\n",
    "employee_df.reindex(new_index) # change some indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `concat` to Add Rows to a DataFrame\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_entry_list = [{\"First\":\"Jason\", \"Last\":\"Moss\", \"Age\":34}]\n",
    "new_entry_df = pd.DataFrame(new_entry_list, index = [\"Employee_3\"], columns = employee_df.columns)\n",
    "new_entry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# form a new dataframe which is a concatenation of 2 separate dataframes \n",
    "employee_df = pd.concat([employee_df, new_entry_df])\n",
    "\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `append` to Add Rows to a DataFrame\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.append.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_entry_list = [{\"First\":\"Jason\", \"Last\":\"Moss\", \"Age\":34}]\n",
    "new_entry_df = pd.DataFrame(new_entry_list, index = [\"Employee_4\"], columns = employee_df.columns)\n",
    "new_entry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append new dataframe to bottom \n",
    "employee_df = employee_df.append(new_entry_df)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entry_series = pd.Series([\"Paul\", \"Trowbridge\", 29], index = [\"First\", \"Last\", \"Age\"])\n",
    "new_entry_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append new series to bottom\n",
    "employee_df = employee_df.append(new_entry_series, ignore_index = True)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.loc` to Add Rows to a DataFrame\n",
    "\n",
    "Since `len(df)` returns the number of rows in a DataFrame and the last row is accessed by `df.loc[len(df)-1]`, we can access a new row below the last one using `df.loc[len(df)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.loc[len(employee_df)] = [\"Paul\", \"Trowbridge\", 40]\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.rename(index=({3:\"Employee_4\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Elements - Series\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = pd.Series(np.arange(3,8), index = [\"a\", \"b\", \"c\", \"d\", 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = series_1.drop([\"a\"]) # delete the \"a\" row \n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_1 = series_1.drop(series_1.index[0]) # delete the first index of the new indexes (\"b\" row)\n",
    "series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows - DataFrames\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df = employee_df.drop([\"Employee_2\"]) # delete the \"Employee_2\" row \n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df = employee_df.drop(employee_df.index[1]) # delete the second index of the new indexes (\"Employee_3\" row)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns - DataFrames\n",
    "\n",
    "We can also use `.drop` to remove columns from a DataFrame, by setting the `axis` parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = employee_df.drop(['Last'], axis=1)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Rows by Values in a Column - DataFrames\n",
    "\n",
    "Documentation: http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.sort_values(by = \"Age\") # sort by Age column in ascending fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.sort_values(by = \"Last\", ascending = False) # sort by First column in descending fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Rows by Index - DataFrames\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.sort_index(axis=0, ascending=False) # sort rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (Manipulating Columns):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming All Columns with a List\n",
    "\n",
    "Method 1 is Explicitly assign the column names (`df.columns = [\"new_col_1\", \"new_col_2\"]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df.columns = [\"First_Name\", \"Last_Name\", \"Age_Years\"]\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Some Columns With A Dictionary\n",
    "\n",
    "Method 2 is Renaming the columns (`df.rename(columns=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.rename(columns = {\"First\":\"First_Name\", \"Last\":\"Last_Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Column Names with `reindex`\n",
    "\n",
    "Method 3 is Re-indexing column names (`df.reindex(columns=)`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_columns = [\"First\", \"First_Name\", \"Last\", \"Last_Name\", \"Age\", \"Age_Years\"]\n",
    "employee_df.reindex(columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Columns\n",
    "\n",
    "Method 1 is Inserting column within the DataFrame (`df.insert(column_position, column = \"new_col_name\", value = )`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.insert(2, column = \"Salary\", value = [100, 200, 150])\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New Columns\n",
    "\n",
    "Method 2 is Adding column to the end of the DataFrame (`df[\"new_col_name\"] = pd.Series()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_series = pd.Series([100,200,150], index = employee_df.index)\n",
    "new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "employee_df[\"Salary\"] = new_series\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns with `del`\n",
    "\n",
    "Method 1 is Deleting column using `del` (`del df[\"col_name\"]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del employee_df[\"Age\"]\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns with `pop`\n",
    "\n",
    "Method 2 is Deleting column using `pop` (`df.pop(\"col_name\")`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last = employee_df.pop(\"Last\")\n",
    "print(last)\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns with `drop`\n",
    "\n",
    "Method 3 is Removing columns using `drop` (`df.drop([\"col_name_1\", \"col_name_5\"])`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.drop([\"First\", \"Last\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Column Names \n",
    "\n",
    "Method 1 is Sorting columns based on column names (`df.sort_index(axis=1)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = my_df = pd.read_csv(\"csv_file_for_pandas.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "employee_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "351px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
